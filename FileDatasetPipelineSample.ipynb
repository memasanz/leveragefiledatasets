{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d31031",
   "metadata": {},
   "source": [
    "## Azure ML - Sample Pipeline for File Dataset Creation/Consumption\n",
    "This notebook demonstrates creation and execution of an Azure ML pipeline designed to create pandas dataframes filled with random data and save these as CSVs to a File Dataset. This File Dataset is subsequently consumed both as a mount and a download in downstream steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fba5e8",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8767170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData, PipelineEndpoint\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169cd843",
   "metadata": {},
   "source": [
    "### Connect to Azure ML Workspace, Provision Compute Resources, and get References to Datastores\n",
    "Connect to workspace using config associated config file. Get a reference to you pre-existing AML compute cluster or provision a new cluster to facilitate processing. Finally, get references to your default blob datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc8ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an existing cluster, using it instead.\n"
     ]
    }
   ],
   "source": [
    "#Connect to AML Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# #Select AML Compute Cluster\n",
    "cpu_cluster_name = 'mm-cluster-new'\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found an existing cluster, using it instead.')\n",
    "except ComputeTargetException:\n",
    "    pipeline_cluster = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3_V2',\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=1)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    \n",
    "#Get default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bfa798",
   "metadata": {},
   "source": [
    " ### Create Run Configuration\n",
    "The `RunConfiguration` defines the environment used across all python steps. You can optionally add additional conda or pip packages to be added to your environment. [More details here](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc08a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./datasets/jsonl/example_0.jsonl' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./datasets/spamformodel.csv')\n",
    "\n",
    "for x in range(0, 1):\n",
    "    df_temp = df.iloc[:x,:x+100]\n",
    "    text = df.to_json(orient='records', lines=True)\n",
    "    textfile = open(\"./datasets/jsonl/example_\" + str(x) + \".jsonl\", \"w\")\n",
    "    print(textfile)\n",
    "    a = textfile.write(text)\n",
    "    textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "041ac035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/tree.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./datasets/tree.yaml\n",
    "\n",
    "treeroot:\n",
    "    branch1:\n",
    "        name: Node 1\n",
    "        branch1-1:\n",
    "            name: Node 1-1\n",
    "    branch2:\n",
    "        name: Node 2\n",
    "        branch2-1:\n",
    "            name: Node 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc028d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    registered_env_name = 'env'\n",
    "    conda_yml_file = 'textclassification_env.yml'\n",
    "    env = Environment.from_conda_specification(registered_env_name, conda_yml_file)\n",
    "    env.register(workspace=ws)\n",
    "    registered_env = Environment.get(ws, registered_env_name)\n",
    "    pipeline_run_config = RunConfiguration()\n",
    "    \n",
    "    # Use the compute you created above. \n",
    "    pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "    # Assign the environment to the run configuration\n",
    "    pipeline_run_config.environment = registered_env\n",
    "    print (\"Run configuration created.\")\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434e4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./datasets/jsonl/example_0.jsonl\n",
      "Uploaded ./datasets/jsonl/example_0.jsonl, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./datasets/tree.yaml\n",
      "Uploaded ./datasets/tree.yaml, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_8cdbe7c6d8f34dc194377d36b358c8e4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds.upload_files(files=['./datasets/jsonl/example_0.jsonl'], # Upload the diabetes csv files in /data\n",
    "                        target_path= 'datasets2/jsonl', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "default_ds.upload_files(files=['./datasets/tree.yaml'], # Upload the diabetes csv files in /data\n",
    "                        target_path= 'datasets2/yaml', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521e88b",
   "metadata": {},
   "source": [
    "### Define Output Datasets\n",
    "Below we define the configuration for the `FileDataset` that will be passed between steps in our pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066e5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = Dataset.File.from_files((default_ds, \"/datasets2/jsonl/example_0.jsonl\"))\n",
    "input_yaml = Dataset.File.from_files((default_ds, \"/datasets2/yaml/tree.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a6db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_dataset = OutputFileDatasetConfig(name='sample_file_dataset', destination=(default_ds, 'sample_file_dataset/{run-id}')).register_on_complete(name='sample_file_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e069f",
   "metadata": {},
   "source": [
    "### Define Pipeline Steps\n",
    "The pipeline below consists of steps to gather and register data from a remote source, a scoring step where the registered model is used to make predictions on loaded, and a data publish step where scored data can be exported to a remote data source. All of the PythonScriptSteps have a corresponding *.py file which is referenced in the step arguments. Also, any PipelineParameters defined above can be passed to and consumed within these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d50181cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline_step_scripts/register_file_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline_step_scripts/register_file_dataset.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "# Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Register File Dataset\")\n",
    "parser.add_argument(\"--input_json\", type=str, dest='input_json', help='input json dataset')\n",
    "parser.add_argument(\"--input_yaml\", type=str, dest='input_yaml', help='input yaml dataset')\n",
    "parser.add_argument('--sample_file_dataset', dest='sample_file_dataset', required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "input_json = args.input_json\n",
    "input_yaml = args.input_yaml\n",
    "sample_file_dataset = args.sample_file_dataset\n",
    "\n",
    "# Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "# Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "# Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "# Generate random sample data\n",
    "random_df = pd.util.testing.makeDataFrame()\n",
    "print(random_df)\n",
    "\n",
    "random_df2 = pd.util.testing.makeDataFrame()\n",
    "print(random_df2)\n",
    "\n",
    "print(\"input file location\")\n",
    "print(input_json)\n",
    "testObject = pd.read_json(path_or_buf=input_json, lines=True)\n",
    "print(testObject)\n",
    "\n",
    "print('*****************')\n",
    "print(\"input yaml location\")\n",
    "print(input_yaml)\n",
    "\n",
    "\n",
    "\n",
    "with open(input_yaml) as f:\n",
    "    # use safe_load instead load\n",
    "    dataMap = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "# Save file dataset\n",
    "os.makedirs(sample_file_dataset, exist_ok=True)\n",
    "random_df.to_csv(os.path.join(sample_file_dataset, 'sample_data.csv'))\n",
    "random_df2.to_csv(os.path.join(sample_file_dataset, 'sample_data_2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c29e2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_data_step = PythonScriptStep(\n",
    "    name='Register File Dataset',\n",
    "    script_name='register_file_dataset.py',\n",
    "    arguments=[\n",
    "        '--input_json', input_json.as_named_input('input_json').as_download(),\n",
    "        '--input_yaml', input_yaml.as_named_input('input_yaml').as_download(),\n",
    "        '--sample_file_dataset', sample_file_dataset,\n",
    "    ],\n",
    "    #inputs=[input_json],\n",
    "    outputs=[sample_file_dataset],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")\n",
    "\n",
    "consume_data_as_download_step = PythonScriptStep(\n",
    "    name='Consume File Dataset as Download',\n",
    "    script_name='consume_file_dataset_as_download.py',\n",
    "    arguments=[\n",
    "        '--local_download_dir', './tmpdir'\n",
    "    ],\n",
    "    inputs=[sample_file_dataset.as_input(name='sample_file_dataset').as_download('./tmpdir')],\n",
    "    outputs=[],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")\n",
    "\n",
    "consume_data_as_mount_step = PythonScriptStep(\n",
    "    name='Consume File Dataset as Mount',\n",
    "    script_name='consume_file_dataset_as_mount.py',\n",
    "    arguments=[],\n",
    "    inputs=[sample_file_dataset.as_input(name='sample_file_dataset').as_mount()],\n",
    "    outputs=[],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935994e",
   "metadata": {},
   "source": [
    "### Create Pipeline\n",
    "Create an Azure ML Pipeline by specifying the steps to be executed. Note: based on the dataset dependencies between steps, exection occurs logically such that no step will execute unless all of the necessary input datasets have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d096f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[register_data_step, consume_data_as_download_step, consume_data_as_mount_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0107f3",
   "metadata": {},
   "source": [
    "### Create Experiment and Run Pipeline\n",
    "Define a new experiment (logical container for pipeline runs) and execute the pipeline. You can modify the values of pipeline parameters here when submitting a new run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d7f3d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Register File Dataset [e8012e10][1967c230-3139-46fd-861c-067c33514b5f], (This step will run and generate new outputs)\n",
      "Created step Consume File Dataset as Download [21aaa857][3048d4ad-c40e-4767-8741-480792894076], (This step will run and generate new outputs)\n",
      "Created step Consume File Dataset as Mount [4abd9c7a][76cbf0da-e673-408b-b6a4-4e6668010c73], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 3f1024b8-f993-420f-99f5-2927de4f6c51\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/3f1024b8-f993-420f-99f5-2927de4f6c51?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "PipelineRunId: 3f1024b8-f993-420f-99f5-2927de4f6c51\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/3f1024b8-f993-420f-99f5-2927de4f6c51?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: dee6e54f-169f-48cc-b1c4-f76e9593cbb3\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/dee6e54f-169f-48cc-b1c4-f76e9593cbb3?wsid=/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "StepRun( Register File Dataset ) Status: NotStarted\n",
      "StepRun( Register File Dataset ) Status: Running\n",
      "\n",
      "StepRun(Register File Dataset) Execution Summary\n",
      "=================================================\n",
      "StepRun( Register File Dataset ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "AzureMLCompute job failed.\n",
      "ExecutionFailed: [REDACTED]\n",
      "\texit_codes: 1\n",
      "\tAppinsights Reachable: Some(true)\n",
      "Execution failed. User process '/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\n",
      "  File \"register_file_\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"register_file_dataset.py\\\", line 50, in <module>\\n    dataMap = yaml.safe_load(f)\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\", line 125, in safe_load\\n    return load(stream, SafeLoader)\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\", line 81, in load\\n    return loader.get_single_data()\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/constructor.py\\\", line 49, in get_single_data\\n    node = self.get_single_node()\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/composer.py\\\", line 39, in get_single_node\\n    if not self.check_event(StreamEndEvent):\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\", line 98, in check_event\\n    self.current_event = self.state()\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\", line 171, in parse_document_start\\n    raise ParserError(None, None,\\nyaml.parser.ParserError: expected '<document start>', but found '{'\\n  in \\\"/mnt/azureml/cr/j/96b30169937344c2ac399ae35070bd03/cap/data-capability/wd/INPUT_input_yaml/example_0.jsonl\\\", line 2, column 1\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"register_file_dataset.py\\\\\\\", line 50, in <module>\\\\n    dataMap = yaml.safe_load(f)\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\\\\\", line 125, in safe_load\\\\n    return load(stream, SafeLoader)\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\\\\\", line 81, in load\\\\n    return loader.get_single_data()\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/constructor.py\\\\\\\", line 49, in get_single_data\\\\n    node = self.get_single_node()\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/composer.py\\\\\\\", line 39, in get_single_node\\\\n    if not self.check_event(StreamEndEvent):\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\\\\\", line 98, in check_event\\\\n    self.current_event = self.state()\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\\\\\", line 171, in parse_document_start\\\\n    raise ParserError(None, None,\\\\nyaml.parser.ParserError: expected '<document start>', but found '{'\\\\n  in \\\\\\\"/mnt/azureml/cr/j/96b30169937344c2ac399ae35070bd03/cap/data-capability/wd/INPUT_input_yaml/example_0.jsonl\\\\\\\", line 2, column 1\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment \u001b[38;5;241m=\u001b[39m Experiment(ws, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_dataset_testing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(pipeline)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:738\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    744\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:831\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_details)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"register_file_dataset.py\\\", line 50, in <module>\\n    dataMap = yaml.safe_load(f)\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\", line 125, in safe_load\\n    return load(stream, SafeLoader)\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\", line 81, in load\\n    return loader.get_single_data()\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/constructor.py\\\", line 49, in get_single_data\\n    node = self.get_single_node()\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/composer.py\\\", line 39, in get_single_node\\n    if not self.check_event(StreamEndEvent):\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\", line 98, in check_event\\n    self.current_event = self.state()\\n  File \\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\", line 171, in parse_document_start\\n    raise ParserError(None, None,\\nyaml.parser.ParserError: expected '<document start>', but found '{'\\n  in \\\"/mnt/azureml/cr/j/96b30169937344c2ac399ae35070bd03/cap/data-capability/wd/INPUT_input_yaml/example_0.jsonl\\\", line 2, column 1\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"register_file_dataset.py\\\\\\\", line 50, in <module>\\\\n    dataMap = yaml.safe_load(f)\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\\\\\", line 125, in safe_load\\\\n    return load(stream, SafeLoader)\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/__init__.py\\\\\\\", line 81, in load\\\\n    return loader.get_single_data()\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/constructor.py\\\\\\\", line 49, in get_single_data\\\\n    node = self.get_single_node()\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/composer.py\\\\\\\", line 39, in get_single_node\\\\n    if not self.check_event(StreamEndEvent):\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\\\\\", line 98, in check_event\\\\n    self.current_event = self.state()\\\\n  File \\\\\\\"/azureml-envs/azureml_87856afa2bfd1e928f01779ebba2a100/lib/python3.8/site-packages/yaml/parser.py\\\\\\\", line 171, in parse_document_start\\\\n    raise ParserError(None, None,\\\\nyaml.parser.ParserError: expected '<document start>', but found '{'\\\\n  in \\\\\\\"/mnt/azureml/cr/j/96b30169937344c2ac399ae35070bd03/cap/data-capability/wd/INPUT_input_yaml/example_0.jsonl\\\\\\\", line 2, column 1\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(ws, 'file_dataset_testing')\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a407a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
